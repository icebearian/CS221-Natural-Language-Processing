{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1T0pJIXSBvEieUZrg46FcV82d1iD5gvsl",
      "authorship_tag": "ABX9TyMPaTEKjHgDx5fHXRFRkJ+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icebearian/CS221-Natural-Language-Processing/blob/master/Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "luz3wroe3NJY",
        "outputId": "de206b81-1fc2-45de-f8a7-6a98a1aaa738"
      },
      "source": [
        "class TextStats:\r\n",
        "  def __init__(self,text):\r\n",
        "    self.text = text\r\n",
        "    \r\n",
        " \r\n",
        "  def stat(self):\r\n",
        "    self.Dic = {}\r\n",
        "    f = open(self.text,encoding = 'utf-8')\r\n",
        "    for i in f:\r\n",
        "      word = i.split()\r\n",
        "      for i in word:\r\n",
        "        if i in self.Dic:\r\n",
        "          self.Dic[i] = \"\"\r\n",
        "        else:\r\n",
        "          self.Dic[i] = \"\"\r\n",
        "    print(self.Dic)\r\n",
        "    f.close()\r\n",
        "\r\n",
        "  def top(self,k):\r\n",
        "    self.Sort = sorted(self.Dic.items(), key=lambda x: x[1], reverse=True)\r\n",
        "    print(self.Sort)\r\n",
        "    for i in range(k):\r\n",
        "      print(self.Sort[i])\r\n",
        "\r\n",
        "  def save(self):\r\n",
        "    Save = dict(self.Sort)\r\n",
        "    with open(\"OUTPUT.txt\",'w',encoding = 'utf-8') as f:\r\n",
        "      for x,y in Save.items():\r\n",
        "          f.write(str(x))\r\n",
        "          f.write(\" \")\r\n",
        "          f.write(str(y))\r\n",
        "          f.write(\"\\n\")\r\n",
        "\r\n",
        "\r\n",
        "s = \"Words.txt\"\r\n",
        "f  =TextStats(s)\r\n",
        "f.stat()\r\n",
        "f.save()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d2117623ade2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Words.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mf\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0mTextStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-d2117623ade2>\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Words.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu4Kv4p8cF2C",
        "outputId": "643e7e02-61db-420a-a622-e61694091958"
      },
      "source": [
        "f= open(\"OUTPUT.txt\",'r',encoding='UTF-8')\r\n",
        "L = []\r\n",
        "for i in range(249):\r\n",
        "  L.append(f.readline())\r\n",
        "D1 = [s.replace('\\n', '') for s in L]\r\n",
        "D2 = [s.replace(' ', '') for s in D1]\r\n",
        "def max_match(sentence, dictionary):\r\n",
        "    if not sentence:\r\n",
        "        return \"\"\r\n",
        "    for i in range(len(sentence), -1, -1):\r\n",
        "        first_word = sentence[:i]\r\n",
        "        remainder = sentence[i:]\r\n",
        "        new = \"\"\r\n",
        "        if len(first_word) > 0:\r\n",
        "          new = first_word[0]\r\n",
        "          for i in range(1,len(first_word)):\r\n",
        "            if first_word[i] != len(first_word) :\r\n",
        "              new += \"_\" +first_word[i]  \r\n",
        "\r\n",
        "        #print(new)\r\n",
        "        if new in dictionary:\r\n",
        "            return new + \" \" + max_match(remainder, dictionary)\r\n",
        "    first_word = sentence[0]\r\n",
        "    print(first_word)\r\n",
        "    remainder = sentence[1:]\r\n",
        "    return first_word + \" \" + max_match(remainder, dictionary)\r\n",
        "sen =  \"chấp hành nghiêm các quy định về phòng chống dịch bệnh vệ sinh dịch tễ\".split()\r\n",
        "gold = \"chấp_hành nghiêm các quy_định về phòng_chống dịch_bệnh vệ_sinh dịch_tễ\".split()\r\n",
        "token = max_match(sen, D2).split()\r\n",
        "print(token)\r\n",
        "n = 0 # Số từ tách đúng \r\n",
        "N = len(token) # Tổng số từ của kết quả tách từ\r\n",
        "M = len(gold) # Tổng số từ của dữ liệu mẫu\r\n",
        "for i in range(len(token)):\r\n",
        "  if token[i] in gold:\r\n",
        "    n += 1\r\n",
        "print(n,N,M)\r\n",
        "print(\"Độ chính xác P: \", n/N)\r\n",
        "print(\"Độ phủ R      : \", n/M)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chấp\n",
            "hành\n",
            "quy\n",
            "định\n",
            "vệ\n",
            "sinh\n",
            "tễ\n",
            "['chấp', 'hành', 'nghiêm', 'các', 'quy', 'định', 'về', 'phòng_chống', 'dịch', 'bệnh', 'vệ', 'sinh', 'dịch', 'tễ']\n",
            "4 14 9\n",
            "Độ chính xác P:  0.2857142857142857\n",
            "Độ phủ R      :  0.4444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}